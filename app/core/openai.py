"""
OpenAI API endpoints
"""

import time
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Any
from fastapi import APIRouter, Header, HTTPException
from fastapi.responses import StreamingResponse
import httpx

from app.core.config import settings
from app.models.schemas import OpenAIRequest, Message, ModelsResponse, Model
from app.utils.helpers import debug_log
from app.core.zai_transformer import ZAITransformer, generate_uuid
# from app.utils.sse_tool_handler import SSEToolHandler  # å·²ç§»é™¤å·¥å…·å¤„ç†å™¨çš„ä½¿ç”¨

router = APIRouter()

# å…¨å±€è½¬æ¢å™¨å®ä¾‹
transformer = ZAITransformer()


@router.get("/v1/models")
async def list_models():
    """List available models"""
    current_time = int(time.time())
    response = ModelsResponse(
        data=[
            Model(id=settings.PRIMARY_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.THINKING_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.SEARCH_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.AIR_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.GLM_46_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.GLM_46_THINKING_MODEL, created=current_time, owned_by="z.ai"),
        ]
    )
    return response


@router.post("/v1/chat/completions")
async def chat_completions(request: OpenAIRequest, authorization: str = Header(...)):
    """Handle chat completion requests with ZAI transformer"""
    role = request.messages[0].role if request.messages else "unknown"
    debug_log(f"ğŸ˜¶â€ğŸŒ«ï¸ æ”¶åˆ° å®¢æˆ·ç«¯ è¯·æ±‚ - æ¨¡å‹: {request.model}, æµå¼: {request.stream}, æ¶ˆæ¯æ•°: {len(request.messages)}, è§’è‰²: {role}, å·¥å…·æ•°: {len(request.tools) if request.tools else 0}")
    
    try:
        # Validate API key (skip if SKIP_AUTH_TOKEN is enabled)
        if not settings.SKIP_AUTH_TOKEN:
            if not authorization.startswith("Bearer "):
                raise HTTPException(status_code=401, detail="Missing or invalid Authorization header")
            
            api_key = authorization[7:]
            if api_key != settings.AUTH_TOKEN:
                raise HTTPException(status_code=401, detail="Invalid API key")
            
        # ä½¿ç”¨æ–°çš„è½¬æ¢å™¨è½¬æ¢è¯·æ±‚
        request_dict = request.model_dump()
        debug_log("ğŸ”„ å¼€å§‹è½¬æ¢è¯·æ±‚æ ¼å¼: OpenAI -> Z.AI")
        
        transformed = await transformer.transform_request_in(request_dict)

        # è°ƒç”¨ä¸Šæ¸¸API
        async def stream_response():
            """æµå¼å“åº”ç”Ÿæˆå™¨ï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰"""
            retry_count = 0
            last_error = None
            current_token = transformed.get("token", "")  # è·å–å½“å‰ä½¿ç”¨çš„token

            while retry_count <= settings.MAX_RETRIES:
                try:
                    # å¦‚æœæ˜¯é‡è¯•ï¼Œé‡æ–°è·å–ä»¤ç‰Œå¹¶æ›´æ–°è¯·æ±‚
                    if retry_count > 0:
                        delay = 2.0
                        debug_log(f"é‡è¯•è¯·æ±‚ ({retry_count}/{settings.MAX_RETRIES}) - ç­‰å¾… {delay:.1f}s")
                        await asyncio.sleep(delay)

                        # æ ‡è®°å‰ä¸€ä¸ªtokenå¤±è´¥
                        if current_token:
                            transformer.mark_token_failure(current_token, Exception(f"Retry {retry_count}: {last_error}"))

                        # é‡æ–°è·å–ä»¤ç‰Œ
                        debug_log("ğŸ”‘ é‡æ–°è·å–ä»¤ç‰Œç”¨äºé‡è¯•...")
                        new_token = await transformer.get_token()
                        if not new_token:
                            debug_log("âŒ é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                            raise Exception("é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                        transformed["config"]["headers"]["Authorization"] = f"Bearer {new_token}"
                        current_token = new_token

                    # é…ç½®ä»£ç†ï¼ˆå¦‚æœæœ‰ï¼‰
                    # httpx ä½¿ç”¨ HTTPS_PROXY ç¯å¢ƒå˜é‡æˆ–ç›´æ¥ä¼ å…¥ proxy å‚æ•°
                    proxy = None
                    if settings.HTTPS_PROXY:
                        proxy = settings.HTTPS_PROXY
                        debug_log(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxy}")
                    elif settings.HTTP_PROXY:
                        proxy = settings.HTTP_PROXY
                        debug_log(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxy}")
                    
                    async with httpx.AsyncClient(timeout=60.0, proxy=proxy) as client:
                        # å‘é€è¯·æ±‚åˆ°ä¸Šæ¸¸
                        # debug_log(f"ğŸ¯ å‘é€è¯·æ±‚åˆ° Z.AI: {transformed['config']['url']}")
                        async with client.stream(
                            "POST",
                            transformed["config"]["url"],
                            json=transformed["body"],
                            headers=transformed["config"]["headers"],
                        ) as response:
                            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                            if response.status_code == 400:
                                # 400 é”™è¯¯ï¼Œè§¦å‘é‡è¯•
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                debug_log(f"âŒ ä¸Šæ¸¸è¿”å› 400 é”™è¯¯ (å°è¯• {retry_count + 1}/{settings.MAX_RETRIES + 1})")
                                debug_log(f"ä¸Šæ¸¸é”™è¯¯å“åº”: {error_msg}")

                                retry_count += 1
                                last_error = f"400 Bad Request: {error_msg}"

                                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºé”™è¯¯
                                    debug_log(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œè¯·æ±‚å¤±è´¥")
                                    error_response = {
                                        "error": {
                                            "message": f"Request failed after {settings.MAX_RETRIES} retries: {last_error}",
                                            "type": "upstream_error",
                                            "code": 400
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return

                            elif response.status_code == 401:
                                # è®¤è¯é”™è¯¯ï¼Œå¯èƒ½éœ€è¦é‡æ–°è·å–token
                                debug_log(f"âŒ è®¤è¯å¤±è´¥ (401)ï¼Œæ ‡è®°tokenå¤±æ•ˆ")
                                if current_token:
                                    transformer.mark_token_failure(current_token, Exception("401 Unauthorized"))
                                
                                retry_count += 1
                                last_error = "401 Unauthorized - Token may be invalid"
                                
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    error_response = {
                                        "error": {
                                            "message": "Authentication failed after retries",
                                            "type": "auth_error",
                                            "code": 401
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return
                            
                            elif response.status_code == 429:
                                # é€Ÿç‡é™åˆ¶ï¼Œå»¶é•¿ç­‰å¾…æ—¶é—´é‡è¯•
                                debug_log(f"âŒ é€Ÿç‡é™åˆ¶ (429)ï¼Œå°†å»¶é•¿ç­‰å¾…æ—¶é—´é‡è¯•")
                                retry_count += 1
                                last_error = "429 Rate Limited"
                                
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    error_response = {
                                        "error": {
                                            "message": "Rate limit exceeded",
                                            "type": "rate_limit_error", 
                                            "code": 429
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return
                            
                            elif response.status_code != 200:
                                # å…¶ä»–é”™è¯¯ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                debug_log(f"âŒ ä¸Šæ¸¸è¿”å›é”™è¯¯: {response.status_code}, è¯¦æƒ…: {error_msg}")
                                
                                # æŸäº›é”™è¯¯å¯ä»¥é‡è¯•
                                retryable_codes = [502, 503, 504]
                                if response.status_code in retryable_codes and retry_count < settings.MAX_RETRIES:
                                    retry_count += 1
                                    last_error = f"{response.status_code}: {error_msg}"
                                    debug_log(f"âš ï¸ æœåŠ¡å™¨é”™è¯¯ {response.status_code}ï¼Œå‡†å¤‡é‡è¯•")
                                    continue
                                
                                # ä¸å¯é‡è¯•çš„é”™è¯¯æˆ–å·²è¾¾åˆ°é‡è¯•ä¸Šé™
                                error_response = {
                                    "error": {
                                        "message": f"Upstream error: {response.status_code}",
                                        "type": "upstream_error",
                                        "code": response.status_code,
                                        "details": error_msg[:500]  # é™åˆ¶é”™è¯¯è¯¦æƒ…é•¿åº¦
                                    }
                                }
                                yield f"data: {json.dumps(error_response)}\n\n"
                                yield "data: [DONE]\n\n"
                                return

                            # 200 æˆåŠŸï¼Œå¤„ç†å“åº”
                            debug_log(f"âœ… Z.AI å“åº”æˆåŠŸï¼Œå¼€å§‹å¤„ç† SSE æµ")
                            if retry_count > 0:
                                debug_log(f"âœ¨ ç¬¬ {retry_count} æ¬¡é‡è¯•æˆåŠŸ")

                            # æ ‡è®°tokenä½¿ç”¨æˆåŠŸ
                            if current_token:
                                transformer.mark_token_success(current_token)

                            # ä¸å†ä½¿ç”¨å¤æ‚çš„å·¥å…·å¤„ç†å™¨ï¼Œç›´æ¥è½¬å‘Z.AIçš„å“åº”
                            has_tools = transformed["body"].get("tools") is not None
                            has_mcp_servers = bool(transformed["body"].get("mcp_servers"))
                            
                            if has_tools or has_mcp_servers:
                                if has_tools and has_mcp_servers:
                                    debug_log(f"ğŸ”§ æ£€æµ‹åˆ°: {len(transformed['body'].get('tools', []))} ä¸ªOpenAIå·¥å…· + {len(transformed['body'].get('mcp_servers', []))} ä¸ªMCPæœåŠ¡å™¨")
                                elif has_tools:
                                    debug_log(f"ğŸ”§ æ£€æµ‹åˆ°: {len(transformed['body'].get('tools', []))} ä¸ªOpenAIå·¥å…·")
                                elif has_mcp_servers:
                                    debug_log(f"ğŸ”§ æ£€æµ‹åˆ°: {len(transformed['body'].get('mcp_servers', []))} ä¸ªMCPæœåŠ¡å™¨")

                            # å¤„ç†çŠ¶æ€
                            has_thinking = False
                            thinking_signature = None
                            first_thinking_chunk = True
                            thinking_closed = False  # è·Ÿè¸ª </think> æ˜¯å¦å·²å‘é€
                            finish_sent = False  # è·Ÿè¸ªæ˜¯å¦å·²å‘é€ finish_chunk
                            done_sent = False  # è·Ÿè¸ªæ˜¯å¦å·²å‘é€ [DONE]

                            # å¤„ç†SSEæµ - ä¼˜åŒ–çš„bufferå¤„ç†
                            buffer = bytearray()
                            incomplete_line = ""
                            line_count = 0
                            chunk_count = 0
                            last_activity = time.time()
                            stream_done = False  # æ ‡è®°æµæ˜¯å¦å·²ç»“æŸ
                            debug_log("ğŸ“¡ å¼€å§‹æ¥æ”¶ SSE æµæ•°æ®...")

                            async for chunk in response.aiter_bytes():
                                if stream_done:
                                    break
                                chunk_count += 1
                                last_activity = time.time()
                                
                                if not chunk:
                                    continue

                                # å°†æ–°æ•°æ®æ·»åŠ åˆ°buffer
                                buffer.extend(chunk)
                                
                                # å°è¯•è§£ç å¹¶å¤„ç†å®Œæ•´çš„è¡Œ
                                try:
                                    # è§£ç ä¸ºå­—ç¬¦ä¸²å¹¶å¤„ç†
                                    text_data = buffer.decode('utf-8')
                                    
                                    # åˆ†å‰²ä¸ºè¡Œ
                                    lines = text_data.split('\n')
                                    
                                    # æœ€åä¸€è¡Œå¯èƒ½ä¸å®Œæ•´ï¼Œä¿å­˜åˆ°incomplete_line
                                    if not text_data.endswith('\n'):
                                        incomplete_line = lines[-1]
                                        lines = lines[:-1]
                                    else:
                                        # å¦‚æœæœ‰æœªå®Œæˆçš„è¡Œï¼Œå°†å…¶ä¸ç¬¬ä¸€è¡Œåˆå¹¶
                                        if incomplete_line:
                                            lines[0] = incomplete_line + lines[0]
                                            incomplete_line = ""
                                    
                                    # æ¸…ç©ºbufferï¼Œå¼€å§‹å¤„ç†æ–°çš„æ•°æ®
                                    buffer = bytearray()
                                    if incomplete_line:
                                        buffer.extend(incomplete_line.encode('utf-8'))
                                    
                                    # å¤„ç†å®Œæ•´çš„è¡Œ
                                    for current_line in lines:
                                        line_count += 1
                                        if not current_line.strip():
                                            continue

                                        if current_line.startswith("data:"):
                                            chunk_str = current_line[5:].strip()
                                            if not chunk_str or chunk_str == "[DONE]":
                                                if chunk_str == "[DONE]":
                                                    # æ”¶åˆ°ä¸Šæ¸¸ [DONE]ï¼Œæ ‡è®°æµç»“æŸ
                                                    debug_log("ğŸ“¡ æ”¶åˆ°ä¸Šæ¸¸ [DONE] ä¿¡å·ï¼Œå‡†å¤‡ç»“æŸæµ")
                                                    stream_done = True
                                                    break  # è·³å‡ºå†…å±‚å¾ªç¯ï¼Œå¤–å±‚å¾ªç¯ä¼šæ£€æŸ¥ stream_done
                                                continue

                                            # æ‰“å° Z.AI è¿”å›çš„åŸå§‹å†…å®¹
                                            debug_log(f"ğŸ“¦ Z.AIåŸå§‹æ•°æ®: {chunk_str[:500]}..." if len(chunk_str) > 500 else f"ğŸ“¦ Z.AIåŸå§‹æ•°æ®: {chunk_str}")

                                            try:
                                                chunk = json.loads(chunk_str)

                                                if chunk.get("type") == "chat:completion":
                                                    data = chunk.get("data", {})
                                                    phase = data.get("phase")

                                                    # è¯¦ç»†è®°å½•æ¯ä¸ªæ•°æ®å—çš„å…³é”®å­—æ®µ
                                                    debug_log(f"ğŸ“Š è§£æç»“æœ: type={chunk.get('type')}, phase={phase}, "
                                                             f"delta_contenté•¿åº¦={len(data.get('delta_content') or '')}, "
                                                             f"edit_contenté•¿åº¦={len(data.get('edit_content') or '')}, "
                                                             f"done={data.get('done')}, usage={bool(data.get('usage'))}")

                                                    # è®°å½•æ¯ä¸ªé˜¶æ®µï¼ˆåªåœ¨é˜¶æ®µå˜åŒ–æ—¶è®°å½•ï¼‰
                                                    if phase and phase != getattr(stream_response, '_last_phase', None):
                                                        debug_log(f"ğŸ“ˆ SSE é˜¶æ®µå˜åŒ–: {getattr(stream_response, '_last_phase', 'None')} -> {phase}")
                                                        stream_response._last_phase = phase

                                                    # å¤„ç†æ€è€ƒå†…å®¹
                                                    if phase == "thinking":
                                                        if not has_thinking:
                                                            has_thinking = True
                                                            # å‘é€åˆå§‹è§’è‰²
                                                            role_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant"},
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        # å¦‚æœä¹‹å‰å·²ç»é—­åˆè¿‡ thinkingï¼Œéœ€è¦é‡æ–°å¼€å§‹æ–°çš„ thinking å—
                                                        if thinking_closed:
                                                            first_thinking_chunk = True
                                                            thinking_closed = False

                                                        delta_content = data.get("delta_content", "")
                                                        if delta_content:
                                                            # å¤„ç†æ€è€ƒå†…å®¹æ ¼å¼
                                                            if delta_content.startswith("<details"):
                                                                content = (
                                                                    delta_content.split("</summary>\n>")[-1].strip()
                                                                    if "</summary>\n>" in delta_content
                                                                    else delta_content
                                                                )
                                                            else:
                                                                content = delta_content

                                                            # ç¬¬ä¸€ä¸ªæ€è€ƒå—æ·»åŠ <think>å¼€å§‹æ ‡ç­¾ï¼Œå…¶ä»–å—ä¿æŒçº¯å†…å®¹
                                                            if first_thinking_chunk:
                                                                formatted_content = f"<think>{content}"
                                                                first_thinking_chunk = False
                                                            else:
                                                                formatted_content = content

                                                            thinking_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "content": formatted_content,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(thinking_chunk)}\n\n"

                                                    # å¤„ç†ç­”æ¡ˆå†…å®¹
                                                    elif phase == "answer":
                                                        edit_content = data.get("edit_content", "")
                                                        delta_content = data.get("delta_content", "")

                                                        # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²ï¼Œå…ˆå‘é€è§’è‰²chunk
                                                        if not has_thinking:
                                                            has_thinking = True  # è®¾ç½®æ ‡å¿—é¿å…é‡å¤å‘é€
                                                            role_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant"},
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            debug_log("â¡ï¸ å‘é€åˆå§‹è§’è‰²chunk")
                                                            yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                                                        if edit_content and "</details>\n" in edit_content:
                                                            if has_thinking and not first_thinking_chunk and not thinking_closed:
                                                                # å‘é€æ€è€ƒç»“æŸæ ‡è®°</think>
                                                                thinking_signature = str(int(time.time() * 1000))
                                                                sig_chunk = {
                                                                    "choices": [
                                                                        {
                                                                            "delta": {
                                                                                "role": "assistant",
                                                                                "content": "</think>",
                                                                            },
                                                                            "finish_reason": None,
                                                                            "index": 0,
                                                                            "logprobs": None,
                                                                        }
                                                                    ],
                                                                    "created": int(time.time()),
                                                                    "id": transformed["body"]["chat_id"],
                                                                    "model": request.model,
                                                                    "object": "chat.completion.chunk",
                                                                    "system_fingerprint": "fp_zai_001",
                                                                }
                                                                yield f"data: {json.dumps(sig_chunk)}\n\n"
                                                                thinking_closed = True  # æ ‡è®°å·²é—­åˆ

                                                            # æå–ç­”æ¡ˆå†…å®¹
                                                            content_after = edit_content.split("</details>\n")[-1]
                                                            if content_after:
                                                                content_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "content": content_after,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(content_chunk)}\n\n"

                                                        # å¤„ç†å¢é‡å†…å®¹
                                                        elif delta_content:
                                                            # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²
                                                            if not has_thinking:
                                                                has_thinking = True  # é¿å…é‡å¤å‘é€
                                                                role_chunk = {
                                                                    "choices": [
                                                                        {
                                                                            "delta": {"role": "assistant"},
                                                                            "finish_reason": None,
                                                                            "index": 0,
                                                                            "logprobs": None,
                                                                        }
                                                                    ],
                                                                    "created": int(time.time()),
                                                                    "id": transformed["body"]["chat_id"],
                                                                    "model": request.model,
                                                                    "object": "chat.completion.chunk",
                                                                    "system_fingerprint": "fp_zai_001",
                                                                }
                                                                debug_log("â¡ï¸ å‘é€åˆå§‹è§’è‰²chunk")
                                                                yield f"data: {json.dumps(role_chunk)}\n\n"

                                                            # å¦‚æœä¹‹å‰åœ¨ thinking é˜¶æ®µä¸”æœªé—­åˆï¼Œå…ˆå‘é€ </think>
                                                            if not first_thinking_chunk and not thinking_closed:
                                                                thinking_end_chunk = {
                                                                    "choices": [
                                                                        {
                                                                            "delta": {
                                                                                "content": "</think>",
                                                                            },
                                                                            "finish_reason": None,
                                                                            "index": 0,
                                                                            "logprobs": None,
                                                                        }
                                                                    ],
                                                                    "created": int(time.time()),
                                                                    "id": transformed["body"]["chat_id"],
                                                                    "model": request.model,
                                                                    "object": "chat.completion.chunk",
                                                                    "system_fingerprint": "fp_zai_001",
                                                                }
                                                                debug_log("â¡ï¸ [answeré˜¶æ®µdelta_content] è¡¥å‘ </think> ç»“æŸæ ‡ç­¾")
                                                                yield f"data: {json.dumps(thinking_end_chunk)}\n\n"
                                                                thinking_closed = True

                                                            content_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "content": delta_content,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            output_data = f"data: {json.dumps(content_chunk)}\n\n"
                                                            # debug_log(f"â¡ï¸ è¾“å‡ºå†…å®¹å—åˆ°å®¢æˆ·ç«¯: {delta_content[:50]}...")
                                                            yield output_data

                                                    # å¤„ç† other é˜¶æ®µ - å¯èƒ½åŒ…å«æ™®é€šå†…å®¹æˆ–å·¥å…·è°ƒç”¨åç»­
                                                    elif phase == "other":
                                                        edit_content = data.get("edit_content", "")
                                                        delta_content = data.get("delta_content", "")

                                                        # ä¼˜å…ˆå¤„ç† edit_contentï¼Œå…¶æ¬¡å¤„ç† delta_content
                                                        content_to_send = ""
                                                        if edit_content:
                                                            # æå– edit_content ä¸­çš„å®é™…å†…å®¹
                                                            if "</details>\n" in edit_content:
                                                                content_to_send = edit_content.split("</details>\n")[-1]
                                                            else:
                                                                content_to_send = edit_content
                                                        elif delta_content:
                                                            content_to_send = delta_content

                                                        # å¦‚æœæœ‰å†…å®¹éœ€è¦è¾“å‡º
                                                        if content_to_send:
                                                            # ç¡®ä¿å·²å‘é€è§’è‰²
                                                            if not has_thinking:
                                                                has_thinking = True
                                                                role_chunk = {
                                                                    "choices": [
                                                                        {
                                                                            "delta": {"role": "assistant"},
                                                                            "finish_reason": None,
                                                                            "index": 0,
                                                                            "logprobs": None,
                                                                        }
                                                                    ],
                                                                    "created": int(time.time()),
                                                                    "id": transformed["body"]["chat_id"],
                                                                    "model": request.model,
                                                                    "object": "chat.completion.chunk",
                                                                    "system_fingerprint": "fp_zai_001",
                                                                }
                                                                debug_log("â¡ï¸ [otheré˜¶æ®µ] å‘é€åˆå§‹è§’è‰²chunk")
                                                                yield f"data: {json.dumps(role_chunk)}\n\n"

                                                            # å¦‚æœä¹‹å‰åœ¨ thinking é˜¶æ®µä¸”æœªé—­åˆï¼Œå…ˆå‘é€ </think>
                                                            if not first_thinking_chunk and not thinking_closed:
                                                                thinking_end_chunk = {
                                                                    "choices": [
                                                                        {
                                                                            "delta": {
                                                                                "content": "</think>",
                                                                            },
                                                                            "finish_reason": None,
                                                                            "index": 0,
                                                                            "logprobs": None,
                                                                        }
                                                                    ],
                                                                    "created": int(time.time()),
                                                                    "id": transformed["body"]["chat_id"],
                                                                    "model": request.model,
                                                                    "object": "chat.completion.chunk",
                                                                    "system_fingerprint": "fp_zai_001",
                                                                }
                                                                debug_log("â¡ï¸ [otheré˜¶æ®µ] è¡¥å‘ </think> ç»“æŸæ ‡ç­¾")
                                                                yield f"data: {json.dumps(thinking_end_chunk)}\n\n"
                                                                thinking_closed = True  # æ ‡è®°å·²é—­åˆ

                                                            content_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "content": content_to_send,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(content_chunk)}\n\n"

                                                    # å¤„ç†å®Œæˆ - å½“æ”¶åˆ°usageä¿¡æ¯æ—¶ï¼ˆdoneä¿¡å·é€šå¸¸ä¼´éšusageï¼‰
                                                    if data.get("usage") and not finish_sent:
                                                        debug_log(f"ğŸ“¦ å®Œæˆå“åº” - ä½¿ç”¨ç»Ÿè®¡: {json.dumps(data['usage'])}")

                                                        # å‘é€å®Œæˆä¿¡å·
                                                        finish_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {},  # ç©ºçš„deltaè¡¨ç¤ºç»“æŸ
                                                                    "finish_reason": "stop",
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "usage": data["usage"],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        finish_output = f"data: {json.dumps(finish_chunk)}\n\n"
                                                        debug_log("â¡ï¸ å‘é€å®Œæˆä¿¡å·")
                                                        yield finish_output
                                                        finish_sent = True
                                                        if not done_sent:
                                                            debug_log("â¡ï¸ å‘é€ [DONE]")
                                                            yield "data: [DONE]\n\n"
                                                            done_sent = True

                                                else:
                                                    # é chat:completion ç±»å‹ï¼Œè®°å½•æ—¥å¿—
                                                    debug_log(f"âš ï¸ æœªå¤„ç†çš„æ¶ˆæ¯ç±»å‹: {chunk.get('type')}, å®Œæ•´å†…å®¹: {chunk_str[:300]}")

                                            except json.JSONDecodeError as e:
                                                debug_log(f"âŒ JSONè§£æé”™è¯¯: {e}, å†…å®¹: {chunk_str[:200]}")
                                            except Exception as e:
                                                debug_log(f"âŒ å¤„ç†chunké”™è¯¯: {e}")
                                
                                except UnicodeDecodeError:
                                    # å¦‚æœè§£ç å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ•°æ®ä¸å®Œæ•´ï¼Œç»§ç»­æ¥æ”¶
                                    debug_log(f"âš ï¸ æ•°æ®è§£ç å¤±è´¥ï¼Œç¼“å†²åŒºå¤§å°: {len(buffer)}")
                                    if len(buffer) > 1024 * 1024:  # 1MBé™åˆ¶
                                        debug_log("âŒ ç¼“å†²åŒºè¿‡å¤§ï¼Œæ¸…ç©ºé‡è¯•")
                                        buffer = bytearray()
                                        incomplete_line = ""
                                except Exception as e:
                                    debug_log(f"âŒ Bufferå¤„ç†å¼‚å¸¸: {e}")
                                    # æ¸…ç©ºbufferç»§ç»­å¤„ç†
                                    buffer = bytearray()
                                    incomplete_line = ""
                                
                                # æ£€æŸ¥æ˜¯å¦é•¿æ—¶é—´æ²¡æœ‰æ´»åŠ¨ï¼ˆè¶…æ—¶æ£€æŸ¥ï¼‰
                                if time.time() - last_activity > 30:  # 30ç§’è¶…æ—¶
                                    debug_log("âš ï¸ æ£€æµ‹åˆ°é•¿æ—¶é—´æ— æ´»åŠ¨ï¼Œå¯èƒ½è¿æ¥ä¸­æ–­")
                                    break

                            # æµç»“æŸæ—¶çš„çŠ¶æ€æ—¥å¿—
                            debug_log(f"ğŸ“‹ æµç»“æŸçŠ¶æ€: stream_done={stream_done}, finish_sent={finish_sent}, "
                                     f"done_sent={done_sent}, has_thinking={has_thinking}, "
                                     f"thinking_closed={thinking_closed}, first_thinking_chunk={first_thinking_chunk}")

                            # ç¡®ä¿å‘é€ç»“æŸä¿¡å·ï¼ˆä»…åœ¨å°šæœªå‘é€æ—¶ï¼‰
                            if not finish_sent:
                                # å¦‚æœæ²¡æœ‰æ”¶åˆ° usageï¼Œä¹Ÿéœ€è¦å‘é€ finish_chunk
                                debug_log("ğŸ“¤ è¡¥å‘ finish_chunkï¼ˆæ—  usageï¼‰")
                                finish_chunk = {
                                    "choices": [
                                        {
                                            "delta": {},
                                            "finish_reason": "stop",
                                            "index": 0,
                                            "logprobs": None,
                                        }
                                    ],
                                    "created": int(time.time()),
                                    "id": transformed["body"]["chat_id"],
                                    "model": request.model,
                                    "object": "chat.completion.chunk",
                                    "system_fingerprint": "fp_zai_001",
                                }
                                yield f"data: {json.dumps(finish_chunk)}\n\n"
                                finish_sent = True

                            if not done_sent:
                                debug_log("ğŸ“¤ å‘é€æœ€ç»ˆ [DONE] ä¿¡å·")
                                yield "data: [DONE]\n\n"
                                done_sent = True

                            debug_log(f"âœ… SSE æµå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {line_count} è¡Œæ•°æ®ï¼Œ{chunk_count} ä¸ªæ•°æ®å—")
                            
                            # ç®€åŒ–çš„å®Œæ•´æ€§æ£€æŸ¥
                            if line_count == 0:
                                debug_log("âš ï¸ æ²¡æœ‰å¤„ç†ä»»ä½•æ•°æ®è¡Œ")
                                if retry_count < settings.MAX_RETRIES:
                                    debug_log("ğŸ”„ å‡†å¤‡é‡è¯•")
                                    retry_count += 1
                                    last_error = "No data received"
                                    continue
                            elif chunk_count > 0:
                                debug_log(f"ğŸ“Š å¹³å‡æ¯ä¸ªæ•°æ®å—åŒ…å« {line_count/chunk_count:.1f} è¡Œ")
                            
                            debug_log("âœ… å“åº”å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
                            
                            # æˆåŠŸå¤„ç†å®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                            return

                except Exception as e:
                    debug_log(f"âŒ æµå¤„ç†é”™è¯¯: {e}")
                    import traceback
                    debug_log(traceback.format_exc())

                    # æ ‡è®°tokenå¤±è´¥
                    if current_token:
                        transformer.mark_token_failure(current_token, e)

                    # æ£€æŸ¥æ˜¯å¦è¿˜å¯ä»¥é‡è¯•
                    retry_count += 1
                    last_error = str(e)

                    if retry_count > settings.MAX_RETRIES:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é”™è¯¯
                        debug_log(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œæµå¤„ç†å¤±è´¥")
                        error_response = {
                            "error": {
                                "message": f"Stream processing failed after {settings.MAX_RETRIES} retries: {last_error}",
                                "type": "stream_error"
                            }
                        }
                        yield f"data: {json.dumps(error_response)}\n\n"
                        yield "data: [DONE]\n\n"
                        return

        # è¿”å›æµå¼å“åº”
        debug_log("ğŸš€ å¯åŠ¨ SSE æµå¼å“åº”")
        
        # åˆ›å»ºä¸€ä¸ªåŒ…è£…çš„ç”Ÿæˆå™¨æ¥è¿½è¸ªæ•°æ®æµ
        async def logged_stream():
            chunk_count = 0
            try:
                debug_log("ğŸ“¤ å¼€å§‹å‘å®¢æˆ·ç«¯æµå¼ä¼ è¾“æ•°æ®...")
                async for chunk in stream_response():
                    chunk_count += 1
                    # debug_log(f"ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk[:200]}..." if len(chunk) > 200 else f"  ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk}")
                    yield chunk
                debug_log(f"âœ… æµå¼ä¼ è¾“å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
            except Exception as e:
                debug_log(f"âŒ æµå¼ä¼ è¾“ä¸­æ–­: {e}")
                raise
        
        return StreamingResponse(
            logged_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        debug_log(f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback

        debug_log(f"âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")